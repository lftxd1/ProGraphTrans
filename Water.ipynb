{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/20204892/miniconda/envs/ly/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,GATConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name='proteinwater'\n",
    "train_csv=pd.read_csv(f'{dir_name}/eSol_train.csv')\n",
    "\n",
    "\n",
    "# train_data=read()\n",
    "train_graphs=[]\n",
    "\n",
    "\n",
    "for index, row in train_csv.iterrows():\n",
    "    name,label,seq=row.values\n",
    "    \n",
    "    vec=torch.from_numpy(np.load(f\"{dir_name}/feature/{name}.npy\")).float()[1:-1,:]\n",
    "    edge_matrix=torch.from_numpy(np.load(f\"{dir_name}/map/{name}.npy\")).float()\n",
    "\n",
    "    row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "\n",
    "\n",
    "    edge = [row.tolist(), col.tolist()]\n",
    "\n",
    "    edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "\n",
    "    label=torch.tensor(label).float()\n",
    "    data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "    train_graphs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_csv=pd.read_csv(f'{dir_name}/eSol_test.csv')\n",
    "\n",
    "\n",
    "# train_data=read()\n",
    "test_graphs=[]\n",
    "\n",
    "\n",
    "for index, row in test_csv.iterrows():\n",
    "    name,label,seq=row.values\n",
    "\n",
    "    vec=torch.from_numpy(np.load(f\"{dir_name}/feature/{name}.npy\")).float()[1:-1,:]\n",
    "    edge_matrix=torch.from_numpy(np.load(f\"{dir_name}/map/{name}.npy\")).float()\n",
    "\n",
    "    row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "\n",
    "\n",
    "    edge = [row.tolist(), col.tolist()]\n",
    "\n",
    "    edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "\n",
    "    label=torch.tensor(label).float()\n",
    "\n",
    "    data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "    test_graphs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "def test(model):\n",
    "\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    correct=0\n",
    "    sums=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_graphs:\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            sums+=1\n",
    "            if out[0]<0.5 and data.y<0.5:\n",
    "                correct+=1\n",
    "            if out[0]>=0.5 and data.y>=0.5:\n",
    "                correct+=1\n",
    "\n",
    "            true_labels.append(data.y.cpu().numpy())\n",
    "            predicted_probs.append(out.cpu().numpy())\n",
    "            \n",
    "    \n",
    "    true_labels = np.array(true_labels).flatten()\n",
    "    predicted_probs = np.array(predicted_probs).flatten()\n",
    "\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(true_labels, predicted_probs))\n",
    "\n",
    "    # R2\n",
    "    r2 = r2_score(true_labels, predicted_probs)\n",
    "\n",
    "    # # Precision, Recall, F1\n",
    "    binary_predictions = (predicted_probs > 0.5).astype(int)\n",
    "    precision = precision_score((true_labels > 0.5).astype(int), binary_predictions)\n",
    "    recall = recall_score((true_labels > 0.5).astype(int), binary_predictions)\n",
    "    f1 = f1_score((true_labels > 0.5).astype(int), binary_predictions)\n",
    "\n",
    "    # # Accuracy\n",
    "    accuracy = correct/sums#accuracy_score((true_labels > 0.5).astype(int), binary_predictions)\n",
    "\n",
    "    # AUC\n",
    "    auc = roc_auc_score((true_labels > 0.5).astype(int), predicted_probs)\n",
    "    #print(correct/sums)\n",
    "    print(f\"RMSE:{rmse:.4f},\",f\"R2:{r2:.4f}|\",f\"Accuracy:{accuracy:.4f},\",f\"Precision:{precision:.4f},\",f\"Recall:{recall:.4f},\",f\"F1:{f1:.4f},\",f\"AUC:{auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "random.shuffle(train_graphs)\n",
    "split_point=int(len(train_graphs)/10*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_graphs=train_graphs[split_point:]\n",
    "train_graphs=train_graphs[:split_point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        assert hid_dim % n_heads == 0\n",
    "\n",
    "        self.w_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.w_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.w_v = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.fc = nn.Linear(hid_dim, hid_dim)\n",
    "\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim // n_heads])).to(device)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        bsz = query.shape[0]\n",
    "\n",
    "        # query = key = value [batch size, sent len, hid dim]\n",
    "\n",
    "        Q = self.w_q(query)\n",
    "        K = self.w_k(key)\n",
    "        V = self.w_v(value)\n",
    "\n",
    "        # Q, K, V = [batch size, sent len, hid dim]\n",
    "\n",
    "        Q = Q.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        K = K.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "        V = V.view(bsz, -1, self.n_heads, self.hid_dim // self.n_heads).permute(0, 2, 1, 3)\n",
    "\n",
    "        # K, V = [batch size, n heads, sent len_K, hid dim // n heads]\n",
    "        # Q = [batch size, n heads, sent len_q, hid dim // n heads]\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "        # energy = [batch size, n heads, sent len_Q, sent len_K]\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        attention = self.do(F.softmax(energy, dim=-1))\n",
    "\n",
    "        # attention = [batch size, n heads, sent len_Q, sent len_K]\n",
    "\n",
    "        x = torch.matmul(attention, V)\n",
    "\n",
    "        # x = [batch size, n heads, sent len_Q, hid dim // n heads]\n",
    "\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # x = [batch size, sent len_Q, n heads, hid dim // n heads]\n",
    "\n",
    "        x = x.view(bsz, -1, self.n_heads * (self.hid_dim // self.n_heads))\n",
    "\n",
    "        # x = [batch size, src sent len_Q, hid dim]\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # x = [batch size, sent len_Q, hid dim]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\" Scaled Dot-Product Attention \"\"\"\n",
    "    def __init__(self, scale):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v,  mask=None):\n",
    "        u = torch.bmm(q, k.transpose(1, 2)) # 1.Matmul\n",
    "        u = u / self.scale # 2.Scale\n",
    "\n",
    "        if mask is not None:\n",
    "            u = u.masked_fill(mask, -np.inf) # 3.Mask\n",
    "        \n",
    "        #print(u.shape,edge_matrix.shape)\n",
    "        #print(u)\n",
    "        #u[0]=u[1]=edge_matrix\n",
    "        attn = self.softmax(u) # 4.Softmax\n",
    "\n",
    "        output = torch.bmm(attn, v) # 5.Output\n",
    "\n",
    "        return output\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" Multi-Head Attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_head, d_k_, d_v_, d_k, d_v, d_o):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.fc_q = nn.Linear(d_k_, n_head * d_k)\n",
    "        self.fc_k = nn.Linear(d_k_, n_head * d_k)\n",
    "        self.fc_v = nn.Linear(d_v_, n_head * d_v)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(scale=np.power(d_k, 0.5))\n",
    "\n",
    "        self.fc_o = nn.Linear(n_head * d_v, d_o)\n",
    "\n",
    "    def forward(self, q, k, v,  mask=None):\n",
    "\n",
    "        n_head, d_q, d_k, d_v = self.n_head, self.d_k, self.d_k, self.d_v\n",
    "\n",
    "        batch, n_q, d_q_ = q.size()\n",
    "        batch, n_k, d_k_ = k.size()\n",
    "        batch, n_v, d_v_ = v.size()\n",
    "\n",
    "        q = self.fc_q(q) # 1.单头变多头\n",
    "        k = self.fc_k(k)\n",
    "        v = self.fc_v(v)\n",
    "        q = q.view(batch, n_q, n_head, d_q).permute(2, 0, 1, 3).contiguous().view(-1, n_q, d_q)\n",
    "        k = k.view(batch, n_k, n_head, d_k).permute(2, 0, 1, 3).contiguous().view(-1, n_k, d_k)\n",
    "        v = v.view(batch, n_v, n_head, d_v).permute(2, 0, 1, 3).contiguous().view(-1, n_v, d_v)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(n_head, 1, 1)\n",
    "        output = self.attention(q, k, v,  mask=mask) # 2.当成单头注意力求输出\n",
    "\n",
    "        output = output.view(n_head, batch, n_q, d_v).permute(1, 2, 0, 3).contiguous().view(batch, n_q, -1) # 3.Concat\n",
    "        output = self.fc_o(output) # 4.仿射变换得到最终输出\n",
    "\n",
    "        return output\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(n_head=4, d_k_=d, d_v_=d, d_k=d, d_v=d, d_o=d)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d)\n",
    "\n",
    "    def forward(self, q,k,v):\n",
    "        # 注意：实际情况中可能还会有一些其他的子层和残差连接\n",
    "        attn_output = self.self_attn(q,k,v)\n",
    "        v = v + attn_output\n",
    "        v = self.norm(v)\n",
    "        return v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features=1280\n",
    "Hidden_feature,lr,weight_decay,batch_size=128,0.0004,0.03,16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792,0.0004,0.03,16\n",
      "0 :\n",
      "RMSE:0.2343, R2:0.4653| Accuracy:0.7831, Precision:0.7429, Recall:0.7645, F1:0.7536, AUC:0.8593\n",
      "1 :\n",
      "RMSE:0.2247, R2:0.5085| Accuracy:0.7908, Precision:0.8273, Recall:0.6686, F1:0.7395, AUC:0.8836\n",
      "2 :\n",
      "RMSE:0.2272, R2:0.4974| Accuracy:0.8023, Precision:0.7405, Recall:0.8459, F1:0.7897, AUC:0.8773\n",
      "3 :\n",
      "RMSE:0.2341, R2:0.4664| Accuracy:0.7651, Precision:0.7752, Recall:0.6715, F1:0.7196, AUC:0.8670\n",
      "4 :\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m     index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(model))\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_graphs:\n\u001b[1;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     sums\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n",
      "File \u001b[0;32m/20204892/miniconda/envs/ly/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    .. function:: to(device=None, dtype=None, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    .. function:: to(dtype, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    .. function:: to(tensor, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m    .. function:: to(memory_format=torch.channels_last)\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    floating point or complex :attr:`dtype`\\ s. In addition, this method will\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    only cast the floating point or complex parameters and buffers to :attr:`dtype`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    (if given). The integral parameters and buffers will be moved\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m    :attr:`device`, if that is given, but with dtypes unchanged. When\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m    :attr:`non_blocking` is set, it tries to convert/move asynchronously\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m    with respect to the host if possible, e.g., moving CPU Tensors with\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    pinned memory to CUDA devices.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    See below for examples.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m        This method modifies the module in-place.\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m        device (:class:`torch.device`): the desired device of the parameters\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m            and buffers in this module\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m        dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m            the parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;03m        tensor (torch.Tensor): Tensor whose dtype and device are the desired\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;124;03m            dtype and device for all parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03m        memory_format (:class:`torch.memory_format`): the desired memory\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;03m            format for 4D parameters and buffers in this module (keyword\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m            only argument)\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03m    Examples::\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \n\u001b[1;32m   1099\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m        >>> linear = nn.Linear(2, 2)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1913, -0.3420],\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;124;03m                [-0.5113, -0.2325]])\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03m        >>> linear.to(torch.double)\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1913, -0.3420],\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;124;03m                [-0.5113, -0.2325]], dtype=torch.float64)\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;124;03m        >>> gpu1 = torch.device(\"cuda:1\")\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;03m        >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1914, -0.3420],\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;124;03m                [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;124;03m        >>> cpu = torch.device(\"cpu\")\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m        >>> linear.to(cpu)\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1914, -0.3420],\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03m                [-0.5112, -0.2324]], dtype=torch.float16)\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m        >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.3741+0.j,  0.2382+0.j],\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03m                [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m        >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;124;03m        tensor([[0.6122+0.j, 0.1150+0.j],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m                [0.6122+0.j, 0.1150+0.j],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m                [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m key\u001b[38;5;241m=\u001b[39mkey1\u001b[38;5;241m+\u001b[39mkey2\u001b[38;5;241m+\u001b[39mkey3\n\u001b[1;32m     31\u001b[0m key\u001b[38;5;241m=\u001b[39mkey\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m query \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index))\n\u001b[1;32m     35\u001b[0m query\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/20204892/miniconda/envs/ly/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    .. function:: to(device=None, dtype=None, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    .. function:: to(dtype, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    .. function:: to(tensor, non_blocking=False)\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m    .. function:: to(memory_format=torch.channels_last)\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m       :noindex:\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    floating point or complex :attr:`dtype`\\ s. In addition, this method will\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    only cast the floating point or complex parameters and buffers to :attr:`dtype`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    (if given). The integral parameters and buffers will be moved\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m    :attr:`device`, if that is given, but with dtypes unchanged. When\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m    :attr:`non_blocking` is set, it tries to convert/move asynchronously\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m    with respect to the host if possible, e.g., moving CPU Tensors with\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    pinned memory to CUDA devices.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    See below for examples.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m        This method modifies the module in-place.\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m        device (:class:`torch.device`): the desired device of the parameters\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m            and buffers in this module\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m        dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;124;03m            the parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;03m        tensor (torch.Tensor): Tensor whose dtype and device are the desired\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;124;03m            dtype and device for all parameters and buffers in this module\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03m        memory_format (:class:`torch.memory_format`): the desired memory\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;03m            format for 4D parameters and buffers in this module (keyword\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m            only argument)\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03m    Examples::\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \n\u001b[1;32m   1099\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m        >>> linear = nn.Linear(2, 2)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1913, -0.3420],\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;124;03m                [-0.5113, -0.2325]])\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03m        >>> linear.to(torch.double)\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1913, -0.3420],\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;124;03m                [-0.5113, -0.2325]], dtype=torch.float64)\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;124;03m        >>> gpu1 = torch.device(\"cuda:1\")\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;03m        >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1914, -0.3420],\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;124;03m                [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;124;03m        >>> cpu = torch.device(\"cpu\")\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m        >>> linear.to(cpu)\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m        Linear(in_features=2, out_features=2, bias=True)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.1914, -0.3420],\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03m                [-0.5112, -0.2324]], dtype=torch.float16)\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m        >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m        >>> linear.weight\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m        Parameter containing:\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;124;03m        tensor([[ 0.3741+0.j,  0.2382+0.j],\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03m                [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m        >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;124;03m        tensor([[0.6122+0.j, 0.1150+0.j],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m                [0.6122+0.j, 0.1150+0.j],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m                [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/20204892/miniconda/envs/ly/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py:324\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    321\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[1;32m    322\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m remove_self_loops(\n\u001b[1;32m    323\u001b[0m         edge_index, edge_attr)\n\u001b[0;32m--> 324\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43madd_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/20204892/miniconda/envs/ly/lib/python3.9/site-packages/torch_geometric/utils/loop.py:466\u001b[0m, in \u001b[0;36madd_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    464\u001b[0m     loop_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     loop_index \u001b[38;5;241m=\u001b[39m \u001b[43mEdgeIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_undirected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m full_edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_index, loop_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse:\n",
      "File \u001b[0;32m/20204892/miniconda/envs/ly/lib/python3.9/site-packages/torch_geometric/edge_index.py:337\u001b[0m, in \u001b[0;36mEdgeIndex.__new__\u001b[0;34m(cls, data, sparse_size, sort_order, is_undirected, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         sparse_size \u001b[38;5;241m=\u001b[39m (sparse_size[\u001b[38;5;241m1\u001b[39m], sparse_size[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_PT112:\n\u001b[0;32m--> 337\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     out \u001b[38;5;241m=\u001b[39m Tensor\u001b[38;5;241m.\u001b[39m_make_subclass(\u001b[38;5;28mcls\u001b[39m, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "# d=Hidden_feature\n",
    "import copy\n",
    "import random\n",
    "\n",
    "for Hidden_feature in [792,264,216,312,600,456]:\n",
    "    for lr in [0.0004,0.001,0.0008,0.0006]:\n",
    "        class GCN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(GCN, self).__init__()\n",
    "                self.conv1 = GATConv(num_node_features, Hidden_feature)\n",
    "                self.conv2 = GATConv(Hidden_feature, Hidden_feature)\n",
    "                self.attention = ScaledDotProductAttention(scale=np.power(Hidden_feature, 0.5))\n",
    "                self.liner1=nn.Linear(num_node_features, Hidden_feature)\n",
    "                self.cnn = nn.Conv1d(num_node_features, Hidden_feature, 3, stride=1, padding=1)\n",
    "                self.mha = TransformerLayer(Hidden_feature)\n",
    "                self.liner2=nn.Linear(Hidden_feature, 1)\n",
    "                self.cnn1 = nn.Conv1d(num_node_features, Hidden_feature, 3, stride=1, padding=1)\n",
    "                self.cnn2 = nn.Conv1d(num_node_features, Hidden_feature, 5, stride=1, padding=2)\n",
    "                self.cnn3 = nn.Conv1d(num_node_features, Hidden_feature, 7, stride=1, padding=3)\n",
    "            def forward(self, data):\n",
    "                x, edge_index,edge_matrix = data.x, data.edge_index,data.edge_matrix\n",
    "                value=F.relu(self.liner1(x))\n",
    "                value=value.unsqueeze(0)\n",
    "\n",
    "\n",
    "                key1=F.relu(self.cnn1(x.transpose(0, 1)).transpose(0, 1))\n",
    "                key2=F.relu(self.cnn2(x.transpose(0, 1)).transpose(0, 1))\n",
    "                key3=F.relu(self.cnn3(x.transpose(0, 1)).transpose(0, 1))\n",
    "                key=key1+key2+key3\n",
    "                key=key.unsqueeze(0)\n",
    "                \n",
    "                x = F.relu(self.conv1(x, edge_index))\n",
    "                query = F.relu(self.conv2(x, edge_index))\n",
    "                query=query.unsqueeze(0)\n",
    "                \n",
    "                \n",
    "                x = self.mha(query,key,value)\n",
    "                x= x.squeeze(0)\n",
    "                x=torch.mean(x, dim=0)\n",
    "                x=self.liner2(x)\n",
    "                x=torch.sigmoid(x)\n",
    "                return x\n",
    "\n",
    "        random.seed(1234)\n",
    "        np.random.seed(1234)\n",
    "        torch.manual_seed(1234)\n",
    "        import copy\n",
    "        train_data=copy.deepcopy(train_graphs)\n",
    "\n",
    "        print(f\"{Hidden_feature},{lr},{weight_decay},{batch_size}\")\n",
    "        model = GCN().cuda()\n",
    "        #optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        import random\n",
    "        max_acc=0\n",
    "        best_model=None\n",
    "        \n",
    "\n",
    "        for epochs in range(10):\n",
    "            optimizer.zero_grad()\n",
    "            losses=0\n",
    "            index=0\n",
    "            random.shuffle(train_data)\n",
    "            model.train()\n",
    "            for idx in range(len(train_data)):\n",
    "                datass=train_data[idx]\n",
    "                datass = datass.cuda()\n",
    "                out = model(datass)\n",
    "                if index==batch_size+1:\n",
    "                    optimizer.zero_grad()\n",
    "                    index=0\n",
    "                \n",
    "                loss = criterion(out.unsqueeze(0), datass.y.unsqueeze(0).unsqueeze(0))\n",
    "                loss.backward()\n",
    "                losses+=loss.item()\n",
    "                if index==batch_size:\n",
    "                    optimizer.step()\n",
    "                \n",
    "                index+=1\n",
    "            print(len(models),\":\")\n",
    "            test(model)\n",
    "            models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.2272, R2:0.4974| Accuracy:0.8023, Precision:0.7405, Recall:0.8459, F1:0.7897, AUC:0.8773\n"
     ]
    }
   ],
   "source": [
    "test(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model=models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_model.cpu(), 'model_mwater_acc_8023.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model_mwater_acc_8023.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
