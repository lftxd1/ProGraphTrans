{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/20204892/miniconda/envs/ly/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,GATConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read():\n",
    "#     proteins=open(\"PDB14189/PDB14189_P.txt\",\"r\").readlines()\n",
    "#     res=[]\n",
    "#     for i in range(0,len(proteins),2):\n",
    "#         name=proteins[i][1:-1]\n",
    "#         seq=proteins[i+1]\n",
    "#         #if name not in names:\n",
    "#         # if len(seq)>1000:\n",
    "#         #     seq=seq[0:1000]\n",
    "#         res.append((name,1))\n",
    "#     return res\n",
    "\n",
    "\n",
    "# train_data=read()\n",
    "# train_graphs=[]\n",
    "# for index,(name,label) in enumerate(train_data):\n",
    "\n",
    "#     vec=torch.from_numpy(np.load(f\"PDB14189/feature/{name}.npy\")).float()[1:-1,:]\n",
    "#     edge_matrix=torch.from_numpy(np.load(f\"PDB14189/map/{name}.npy\")).float()\n",
    "\n",
    "#     row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "\n",
    "\n",
    "#     edge = [row.tolist(), col.tolist()]\n",
    "\n",
    "#     edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "    \n",
    "#     label=torch.tensor(label).float()\n",
    "#     data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "#     train_graphs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read():\n",
    "#     proteins=open(\"PDB14189/PDB14189_N.txt\",\"r\").readlines()\n",
    "#     res=[]\n",
    "#     for i in range(0,len(proteins),2):\n",
    "#         name=proteins[i][1:-1]\n",
    "#         seq=proteins[i+1]\n",
    "#         #if name not in names:\n",
    "#         # if len(seq)>1000:\n",
    "#         #     seq=seq[0:1000]\n",
    "#         res.append((name,0))\n",
    "#     return res\n",
    "\n",
    "\n",
    "# train_data=read()\n",
    "\n",
    "# for index,(name,label) in enumerate(train_data):\n",
    "\n",
    "#     vec=torch.from_numpy(np.load(f\"PDB14189/feature/{name}.npy\")).float()[1:-1,:]\n",
    "#     edge_matrix=torch.from_numpy(np.load(f\"PDB14189/map/{name}.npy\")).float()\n",
    "\n",
    "#     row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "\n",
    "\n",
    "#     edge = [row.tolist(), col.tolist()]\n",
    "\n",
    "#     edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "    \n",
    "#     label=torch.tensor(label).float()\n",
    "#     data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "#     train_graphs.append(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_graphs=[]\n",
    "# def read():\n",
    "#     proteins=open(\"PDB2272/PDB2272_N.txt\",\"r\").readlines()\n",
    "#     res=[]\n",
    "#     for i in range(0,len(proteins),2):\n",
    "#         name=proteins[i][1:-1]\n",
    "#         seq=proteins[i+1]\n",
    "#         res.append((name,0))\n",
    "#     return res\n",
    "\n",
    "# test_data=read()\n",
    "# test_graphs=[]\n",
    "# for index,(name,label) in enumerate(test_data):\n",
    "    \n",
    "#     vec=torch.from_numpy(np.load(f\"PDB2272/feature/{name}.npy\")).float()[1:-1,:]\n",
    "#     edge_matrix=torch.from_numpy(np.load(f\"PDB2272/map/{name}.npy\")).float()\n",
    "\n",
    "#     row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "\n",
    "\n",
    "#     edge = [row.tolist(), col.tolist()]\n",
    "\n",
    "#     edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "    \n",
    "#     label=torch.tensor(label).float()\n",
    "#     data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "#     test_graphs.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def read():\n",
    "#     proteins=open(\"PDB2272/PDB2272_P.txt\",\"r\").readlines()\n",
    "#     res=[]\n",
    "#     for i in range(0,len(proteins),2):\n",
    "#         name=proteins[i][1:-1]\n",
    "#         seq=proteins[i+1]\n",
    "#         res.append((name,1))\n",
    "#     return res\n",
    "\n",
    "# test_data=read()\n",
    "\n",
    "# for index,(name,label) in enumerate(test_data):\n",
    "#     vec=torch.from_numpy(np.load(f\"PDB2272/feature/{name}.npy\")).float()[1:-1,:]\n",
    "#     edge_matrix=torch.from_numpy(np.load(f\"PDB2272/map/{name}.npy\")).float()\n",
    "\n",
    "#     row, col = np.where((edge_matrix >= 0.5) & (np.eye(edge_matrix.shape[0]) == 0))\n",
    "#     edge = [row.tolist(), col.tolist()]\n",
    "#     edge_index=torch.from_numpy(np.array(edge)).long()\n",
    "    \n",
    "#     label=torch.tensor(label).float()\n",
    "#     data=Data(x=vec,edge_index=edge_index,y=label,edge_matrix=edge_matrix)\n",
    "#     test_graphs.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,random\n",
    "train_graphs=pickle.load(open(\"DNAbing_train\",\"rb\"))\n",
    "test_graphs=pickle.load(open(\"DNAbing_test\",\"rb\"))\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\" Scaled Dot-Product Attention \"\"\"\n",
    "    def __init__(self, scale):\n",
    "        super().__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v,  mask=None):\n",
    "        u = torch.bmm(q, k.transpose(1, 2)) # 1.Matmul\n",
    "        u = u / self.scale # 2.Scale\n",
    "\n",
    "        if mask is not None:\n",
    "            u = u.masked_fill(mask, -np.inf) # 3.Mask\n",
    "        \n",
    "        #print(u.shape,edge_matrix.shape)\n",
    "        #print(u)\n",
    "        #u[0]=u[1]=edge_matrix\n",
    "        attn = self.softmax(u) # 4.Softmax\n",
    "\n",
    "        output = torch.bmm(attn, v) # 5.Output\n",
    "\n",
    "        return output\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" Multi-Head Attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_head, d_k_, d_v_, d_k, d_v, d_o):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.fc_q = nn.Linear(d_k_, n_head * d_k)\n",
    "        self.fc_k = nn.Linear(d_k_, n_head * d_k)\n",
    "        self.fc_v = nn.Linear(d_v_, n_head * d_v)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(scale=np.power(d_k, 0.5))\n",
    "\n",
    "        self.fc_o = nn.Linear(n_head * d_v, d_o)\n",
    "\n",
    "    def forward(self, q, k, v,  mask=None):\n",
    "\n",
    "        n_head, d_q, d_k, d_v = self.n_head, self.d_k, self.d_k, self.d_v\n",
    "\n",
    "        batch, n_q, d_q_ = q.size()\n",
    "        batch, n_k, d_k_ = k.size()\n",
    "        batch, n_v, d_v_ = v.size()\n",
    "\n",
    "        q = self.fc_q(q) # 1.单头变多头\n",
    "        k = self.fc_k(k)\n",
    "        v = self.fc_v(v)\n",
    "        q = q.view(batch, n_q, n_head, d_q).permute(2, 0, 1, 3).contiguous().view(-1, n_q, d_q)\n",
    "        k = k.view(batch, n_k, n_head, d_k).permute(2, 0, 1, 3).contiguous().view(-1, n_k, d_k)\n",
    "        v = v.view(batch, n_v, n_head, d_v).permute(2, 0, 1, 3).contiguous().view(-1, n_v, d_v)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(n_head, 1, 1)\n",
    "        output = self.attention(q, k, v,  mask=mask) # 2.当成单头注意力求输出\n",
    "\n",
    "        output = output.view(n_head, batch, n_q, d_v).permute(1, 2, 0, 3).contiguous().view(batch, n_q, -1) # 3.Concat\n",
    "        output = self.fc_o(output) # 4.仿射变换得到最终输出\n",
    "\n",
    "        return output\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(n_head=4, d_k_=d, d_v_=d, d_k=d, d_v=d, d_o=d)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(d)\n",
    "\n",
    "    def forward(self, q,k,v):\n",
    "        # 注意：实际情况中可能还会有一些其他的子层和残差连接\n",
    "        attn_output = self.self_attn(q,k,v)\n",
    "        v = v + attn_output\n",
    "        v = self.norm(v)\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve,mean_squared_error, r2_score, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def testwithtrain(model,test_data):\n",
    "    #global logs\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    correct=0\n",
    "    sums=0\n",
    "    #model=model.cpu()\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            sums+=1\n",
    "            if out[0]<0.5 and data.y<0.5:\n",
    "                correct+=1\n",
    "            if out[0]>=0.5 and data.y>=0.5:\n",
    "                correct+=1\n",
    "\n",
    "            true_labels.append(data.y.cpu().numpy())\n",
    "            predicted_probs.append(out.cpu().numpy())\n",
    "            \n",
    "    #model=model.cuda()\n",
    "    true_labels = np.array(true_labels).flatten()\n",
    "    predicted_probs = np.array(predicted_probs).flatten()\n",
    "\n",
    "    predicted_labels = (predicted_probs >= 0.5).astype(int)\n",
    "\n",
    "    # 计算混淆矩阵中的 TN, FP, FN, TP\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predicted_labels).ravel()\n",
    "\n",
    "    # 计算准确性 (Accuracy, ACC)\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # 计算敏感性 (Sensitivity, Sen)\n",
    "    sen = tp / (tp + fn)\n",
    "\n",
    "    # 计算特异性 (Specificity, Spe)\n",
    "    spe = tn / (tn + fp)\n",
    "\n",
    "    # 计算 Matthew 相关系数 (Matthew's Correlation Coefficient, MCC)\n",
    "    mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
    "\n",
    "    print(f'ACC: {acc}',end=\"|\")\n",
    "    print(f'Sen: {sen}',end=\"|\")\n",
    "    print(f'Spe: {spe}',end=\"|\")\n",
    "    print(f'MCC: {mcc}')\n",
    "\n",
    "    return acc,sen,spe,mcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GATConv(num_node_features, Hidden_feature)\n",
    "        self.conv2 = GATConv(Hidden_feature, Hidden_feature)\n",
    "        self.attention = ScaledDotProductAttention(scale=np.power(Hidden_feature, 0.5))\n",
    "        self.liner1=nn.Linear(num_node_features, Hidden_feature)\n",
    "        self.cnn1 = nn.Conv1d(num_node_features, Hidden_feature, 3, stride=1, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(num_node_features, Hidden_feature, 5, stride=1, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(num_node_features, Hidden_feature, 7, stride=1, padding=3)\n",
    "        self.mha = TransformerLayer(Hidden_feature)\n",
    "        self.liner2=nn.Linear(Hidden_feature, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index,edge_matrix = data.x, data.edge_index,data.edge_matrix\n",
    "        value=F.relu(self.liner1(x)).unsqueeze(0)\n",
    "        \n",
    "        key1=F.relu(self.cnn1(x.transpose(0, 1)).transpose(0, 1))\n",
    "        key2=F.relu(self.cnn2(x.transpose(0, 1)).transpose(0, 1))\n",
    "        key3=F.relu(self.cnn3(x.transpose(0, 1)).transpose(0, 1))\n",
    "        key=key1+key2+key3\n",
    "        key=key.unsqueeze(0)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        query = F.relu(self.conv2(x, edge_index)).unsqueeze(0)\n",
    "\n",
    "        x = self.mha(key,query,value)\n",
    "        x= x.squeeze(0)\n",
    "\n",
    "        x=torch.mean(x, dim=0)\n",
    "        x=self.liner2(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_graphs:\n",
    "    data=data.cuda()\n",
    "    \n",
    "for data in test_graphs:\n",
    "    data=data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "num_node_features=640\n",
    "Hidden_feature,lr,weight_decay,batch_size=256,0.0005,0.3,16\n",
    "\n",
    "model = GCN().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "import random\n",
    "max_acc=0\n",
    "models=[]\n",
    "\n",
    "model_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 0\n",
      "ACC: 0.8477883781439722|Sen: 0.818733738074588|Spe: 0.8768430182133564|MCC: 0.6967541117958623\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 1\n",
      "ACC: 0.8560277536860365|Sen: 0.8785776235906332|Spe: 0.8334778837814397|MCC: 0.7127807695955982\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 2\n",
      "ACC: 0.8490893321769297|Sen: 0.9132697311361665|Spe: 0.784908933217693|MCC: 0.7040024997252693\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 3\n",
      "ACC: 0.8573287077189939|Sen: 0.8751084128360798|Spe: 0.839549002601908|MCC: 0.7151096764094538\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 4\n",
      "ACC: 0.8772766695576756|Sen: 0.8829141370338248|Spe: 0.8716392020815265|MCC: 0.754601304667603\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 5\n",
      "ACC: 0.883347788378144|Sen: 0.8993928881179531|Spe: 0.8673026886383348|MCC: 0.7670906461402077\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 6\n",
      "ACC: 0.8720728534258456|Sen: 0.9167389418907199|Spe: 0.8274067649609714|MCC: 0.7471328270986896\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 7\n",
      "ACC: 0.8751084128360798|Sen: 0.9132697311361665|Spe: 0.836947094535993|MCC: 0.752411479313726\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 8\n",
      "ACC: 0.8642671292281006|Sen: 0.9167389418907199|Spe: 0.8117953165654813|MCC: 0.7325794357582566\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 9\n",
      "ACC: 0.8660017346053773|Sen: 0.9453599306157849|Spe: 0.7866435385949696|MCC: 0.7414013123269465\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 10\n",
      "ACC: 0.867736339982654|Sen: 0.9436253252385083|Spe: 0.7918473547267997|MCC: 0.7440932884977097\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 11\n",
      "ACC: 0.8829141370338248|Sen: 0.9384215091066782|Spe: 0.8274067649609714|MCC: 0.7705914854251882\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 12\n",
      "ACC: 0.867736339982654|Sen: 0.9462272333044233|Spe: 0.7892454466608847|MCC: 0.7447059178486666\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 13\n",
      "ACC: 0.8746747614917606|Sen: 0.9384215091066782|Spe: 0.810928013876843|MCC: 0.7555149734170384\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 14\n",
      "ACC: 0.8837814397224631|Sen: 0.9366869037294016|Spe: 0.8308759757155247|MCC: 0.771896098232524\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 15\n",
      "ACC: 0.8785776235906332|Sen: 0.9366869037294016|Spe: 0.8204683434518647|MCC: 0.7623209905381968\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 16\n",
      "ACC: 0.8811795316565482|Sen: 0.9453599306157849|Spe: 0.8169991326973114|MCC: 0.7687182574639897\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 17\n",
      "ACC: 0.8811795316565482|Sen: 0.9254119687771032|Spe: 0.836947094535993|MCC: 0.7653598117796186\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 18\n",
      "ACC: 0.8824804856895057|Sen: 0.9418907198612315|Spe: 0.8230702515177797|MCC: 0.7704188070478726\n",
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|Test: 19\n",
      "ACC: 0.8768430182133564|Sen: 0.9358196010407632|Spe: 0.8178664353859497|MCC: 0.7589843855253574\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    losses=0\n",
    "    index=0\n",
    "    model=model.cuda()\n",
    "    \n",
    "    model.train()\n",
    "    for idx in range(len(train_graphs)):\n",
    "        datass=train_graphs[idx]\n",
    "        out = model(datass)\n",
    "        loss = criterion(out.unsqueeze(0), datass.y.unsqueeze(0).unsqueeze(0))\n",
    "        loss.backward()\n",
    "        losses+=loss.item()\n",
    "        if index==batch_size:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            index=0\n",
    "        if idx%1000==0:\n",
    "            print(idx,end=\"|\")\n",
    "        index+=1\n",
    "    print(\"Test:\",epochs)\n",
    "    res_test=testwithtrain(model,test_graphs)\n",
    "    model_list.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.883347788378144|Sen: 0.8993928881179531|Spe: 0.8673026886383348|MCC: 0.7670906461402077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.883347788378144, 0.8993928881179531, 0.8673026886383348, 0.7670906461402077)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model=model_list[5]\n",
    "testwithtrain(save_model,test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# weight=pickle.load(open(\"DNAbinding.model\",'rb'))\n",
    "# model.load_state_dict(weight)\n",
    "# res_test=testwithtrain(model,test_graphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
